{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to AsyncIO and Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Understanding Concurrency Models\n",
    "- **Synchronous Execution**: Tasks run sequentially, simple but inefficient for I/O-bound tasks.\n",
    "- **Asynchronous Execution**: Ideal for I/O-bound tasks, handled by the asyncio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   
   ],
   "source": [
    "import asyncio\n",
    "async def fetch_data():\n",
    "    await asyncio.sleep(2)\n",
    "    return \"Data fetched\"\n",
    "\n",
    "async def main():\n",
    "    data = await fetch_data()\n",
    "    print(data)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Multithreading and Multiprocessing\n",
    "- **Multithreading**: Effective for I/O-bound tasks but limited by Python's GIL (Global Interpreter Lock).\n",
    "- **Multiprocessing**: Enables true parallelism, best for CPU-bound tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multithreading Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def worker():\n",
    "    print(\"Thread is working\")\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    thread = threading.Thread(target=worker)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def worker():\n",
    "    print(\"Process is working\")\n",
    "\n",
    "processes = []\n",
    "for i in range(5):\n",
    "    process = Process(target=worker)\n",
    "    processes.append(process)\n",
    "    process.start()\n",
    "\n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Creating and Managing Threads\n",
    "- **Thread Lifecycle and States**: You can monitor and manage thread states using `is_alive()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker():\n",
    "    time.sleep(2)\n",
    "    print(\"Worker thread\")\n",
    "\n",
    "thread = threading.Thread(target=worker)\n",
    "print(f\"Before start: {thread.is_alive()}\")\n",
    "thread.start()\n",
    "print(f\"After start: {thread.is_alive()}\")\n",
    "thread.join()\n",
    "print(f\"After join: {thread.is_alive()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Synchronization Mechanisms\n",
    "- Concurrency issues like race conditions, deadlocks, and data corruption are common. You can mitigate these using synchronization primitives like Locks, Semaphores, and Conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "\n",
    "def critical_section():\n",
    "    with lock:\n",
    "        print(\"In critical section\")\n",
    "\n",
    "thread1 = threading.Thread(target=critical_section)\n",
    "thread2 = threading.Thread(target=critical_section)\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Advanced Threading Concepts\n",
    "- **ThreadPoolExecutor** provides efficient thread management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def task(n):\n",
    "    print(f\"Processing {n}\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(task, range(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Asyncio Event Loop and Control Flow\n",
    "The asyncio **event loop** is responsible for scheduling and running asynchronous tasks. Tasks are created with `asyncio.create_task()` and managed by the event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task1():\n",
    "    await asyncio.sleep(1)\n",
    "    return \"Task 1 finished\"\n",
    "\n",
    "async def task2():\n",
    "    await asyncio.sleep(2)\n",
    "    return \"Task 2 finished\"\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(task1())\n",
    "    task2 = asyncio.create_task(task2())\n",
    "    results = await asyncio.gather(task1, task2)\n",
    "    print(results)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Futures in Asynchronous Programming\n",
    "Futures represent a value that may not yet be available, commonly used for managing the results of asynchronous operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_future_value(future):\n",
    "    await asyncio.sleep(1)\n",
    "    future.set_result(\"Future is done\")\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = loop.create_future()\n",
    "    await asyncio.create_task(set_future_value(future))\n",
    "    result = await future\n",
    "    print(result)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Performance and Optimization\n",
    "Efficient concurrency management is key to optimizing Python applications, especially for large or intensive tasks. By using multithreading, multiprocessing, or asyncio appropriately, performance can be enhanced significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction to AsyncIO and Multithreading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
